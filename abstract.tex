

~\\



\begin{addmargin}[1.2cm]{1.2cm}
{\Large\sffamily\bfseries Abstract}
\vspace{0.5cm}

\noindent ``The meaning of a word is its use in the language''. In the
first half of the 20th century Ludwig Wittgenstein introduced this
idea into philosophy and especially in the last few decades, related
disciplines such as psychology and linguistics started embracing the
view that that natural language is a dynamic system of arbitrary and
culturally learnt conventions. From the end of the nineties on,
researchers around Luc Steels transferred this notion of communication
to the field of artificial intelligence by letting software agents and
later robots play so-called language games in order to self-organize
communication systems without requiring prior linguistic or conceptual
knowledge. Continuing and advancing that research, the work presented
in this thesis investigates lexicon formation in humanoid robots,
i.e. the emergence of shared lexical knowledge in populations of
robotic agents. Central to this is the concept of referential
uncertainty, which is the difficulty of guessing a previously unknown
word from the context. First in a simulated environments and later
with physical robots, this work starts from very simple lexicon
formation models and then systematically analyzes how an increasing
complexity in communicative interactions leads to an increasing
complexity of representations and learning mechanisms. We evaluate
lexicon formation models with respect to their robustness, scaling and
their applicability to robotic interaction scenarios and one result of
this work is that the predominating approaches in the literature do
not scale well and are not able to cope with the challenges stemming
from grounding words in the real-world perceptions of physical
robots. In order to overcome these limitations, we present an
alternative lexicon formation model and evaluate its performance.
\end{addmargin}

\cleardoublepage




~\\

\begin{addmargin}[1.2cm]{1.2cm}

{\Large\sffamily\bfseries Zusammenfassung}
\vspace{0.5cm}

\noindent ``Die Bedeutung eines Wortes ist sein Gebrauch in der
Sprache''. Ludwig Wittgenstein führte diese Idee in der ersten Hälfte
des 20. Jahrhunderts in die Philosophie ein und in verwandten
Disziplinen wie der Psychologie und Linguistik setzte sich vor allem
in den letzten Jahrzehnten die Ansicht durch, dass natürliche Sprache
ein dynamisches System arbiträrer und kulturell gelernter Konventionen
ist. Forscher um Luc Steels übertrugen diesen Sprachbegriff seit Ende
der 90er Jahre auf das Gebiet der Künstlichen Intelligenz, indem sie
zunächst Software-Agenten und später Robotern mittels sogenannter
Sprachspiele gemeinsame Kommunikationssysteme bilden liessen, ohne
dass Agenten im Voraus mit linguistischem und konzeptionellen Wissen
ausgestattet werden. Die vorliegende Arbeit knüpft an diese Forschung
an und untersucht vertiefend die Selbstorganisation von geteiltem
lexikalischen Wissen in humanoiden Robotern. Zentral ist dabei das
Konzept der ``referential uncertainty'', d.h. die Schwierigkeit, die
Bedeutung eines bisher unbekannten Wortes aus dem Kontext zu
erschliessen. Ausgehend von sehr einfachen Modellen der Lexikonbildung
untersucht die Arbeit zunächst in einer simulierten Umgebung und
später mit physikalischen Robotern systematisch, wie zunehmende
Komplexität kommunikativer Interaktionen komplexere Lernmodelle und
Reprä\-sentationen erfordert. Ein Ergebnis der Evaluierung der Modelle
hinsichtlich Robustheit und Übertragbarkeit auf Interaktionszenarien
mit Robotern ist, dass die in der Literatur vorwiegenden
selektionistischen Ansätze schlecht skalieren und mit der zusätzlichen
Herausforderung einer Verankerung in visuellen Perzeptionen echter
Roboter nicht zurecht kommen. Davon ausgehend wird ein alternatives
Modell vorgestellt.
\end{addmargin}

\cleardoublepage

\normalsize

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "phd-thesis.tex"
%%% End: 
